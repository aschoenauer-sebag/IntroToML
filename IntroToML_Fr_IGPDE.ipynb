{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction au ML, IGPDE\n",
    "## Alice Schoenauer Sebag, Jan. 2020\n",
    "## Inspection générale des finances, MEF\n",
    "\n",
    "Nous allons nous intéresser à un jeu de données biologiques.\n",
    "\n",
    "## 1. Téléchargement\n",
    "\n",
    "Il s'agit d'un jeu de données publiques [1]. Il a été pré-processé suivant la méthode décrite dans [2]. \n",
    "### Références: \n",
    "[1] [Caie et al., Molecular Cancer Therapeutics, 2010], [Ljosa et al., Nature Methods, 2012]\n",
    "\n",
    "https://data.broadinstitute.org/bbbc/BBBC021/\n",
    "\n",
    "[2] [Kang et al., Nature Biotech., 2016]\n",
    "\n",
    "https://www.nature.com/articles/nbt.3419"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas\n",
    "import numpy as np\n",
    "%matplotlib\n",
    "if not os.path.isfile('IntroToML_TD.tar.gz'):\n",
    "    print('Be patient while the data downloads')\n",
    "    os.system('wget -c http://members.cbio.mines-paristech.fr/~aschoenauer/IntroToML_TD.tar.gz')\n",
    "    os.system('tar -xvzf IntroToML_TD.tar.gz')\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploration des données\n",
    "\n",
    "Nous avons téléchargé deux fichiers :\n",
    "* X (les features)\n",
    "* Y (les classes de médicaments et d'autres métadonnées).\n",
    "\n",
    "Jetons un coup d'oeil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture du fichier\n",
    "Y = pandas.read_csv('IntroToML_TD/Caie_metadata.csv')\n",
    "\n",
    "# Cela montre la \"tête\" du fichier : les 5 premières lignes\n",
    "Y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combien de data points avons-nous ?\n",
    "print('Nb de datapoints:',Y.shape[0])\n",
    "\n",
    "# Combien de médicaments distincts ?\n",
    "print(\"Nb de médicaments différents \", Y.Drug.nunique())\n",
    "\n",
    "# **Question** Combien y a-t-il de \"DrugClass\" distinctes dans les données ?\n",
    "print('Nb de classes ?')\n",
    "# votre réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regardons également la matrice de features\n",
    "X = pandas.read_csv('IntroToML_TD/Caie_features.csv')\n",
    "print(X.head())\n",
    "\n",
    "# **Question** Combien de features dans ce jeu de données ?\n",
    "print('Nb of features?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons essayer de regarder les données à l'aide d'un graphe. Pour que cela soit plus informatif, nous allons commencer par transformer les données, en les projetant sur un nombre réduit d'axes informatifs. Il y a de nombreuses manières de faire cela : une analyse en composantes principales (ACP), un tSNE (t-distributed stochastic neighbor embedding), ou encore une umap (uniform manifold approximation), et beaucoup d'autres.\n",
    "\n",
    "Pour aujourd'hui nous utiliserons une ACP, qui projette les données sur les combinaisons linéaires de features présentant la variance maximale des données. Plus d'infos sur l'ACP : https://fr.wikipedia.org/wiki/Analyse_en_composantes_principales\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as p\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "# Standardisation des données\n",
    "nX = (X-np.mean(X,0))/np.std(X, 0)\n",
    "# On trouve la projection et on projette\n",
    "npX = pca.fit_transform(nX)\n",
    "\n",
    "# Enfin, on représente les données dans le nouvel espace\n",
    "f=p.figure(figsize=(18,18))\n",
    "ax = f.gca(projection='3d')\n",
    "ax.scatter(npX[:,0], npX[:,1], npX[:,2])\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons d'ajouter de l'information sur les classes - plusieurs exemples en fonction des packages installés (le plus courant : *matplotlib*, est parfois moins intuitifs que des packages plus récents, par exemple *seaborn* et *altair*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les classes distinctes\n",
    "distinct_drug_classes = sorted(list(Y.DrugClass.unique()))\n",
    "\n",
    "# Choix de couleurs\n",
    "color_names = ['red', 'blue', 'orange', 'magenta','black',  'green','0.5', '#bcbddc','yellow','cyan', '#a6cee3',\n",
    "               '#dd1c77', '#1f78b4', '#b2df8a', '#33a02c', '#fb9a99', '#e31a1c', '#fdbf6f', '#ff7f00', '#cab2d6', \n",
    "               '#6a3d9a']\n",
    "color_dict = dict(zip(distinct_drug_classes, color_names))\n",
    "\n",
    "# J'assigne une couleur à chaque point en fonction de sa classe\n",
    "Y['color'] = [color_dict[dc] for dc in Y.DrugClass]\n",
    "\n",
    "# On replotte - amusez-vous à tourner le plot\n",
    "f=p.figure(figsize=(18,18))\n",
    "ax = f.gca(projection='3d')\n",
    "ax.scatter(npX[:,0], npX[:,1], npX[:,2], color=Y.color)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarque : les plots en 3D sont souvent trompeurs, car le résultat dépend de l'angle selon lequel on se place.\n",
    "\n",
    "Ajoutons aussi une légende"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, subplots=p.subplots(1, 3, figsize=(15,22))\n",
    "subplots[0].scatter(npX[:,0], npX[:,1], color=Y.color, alpha=0.5)\n",
    "subplots[0].set_xlabel('Principal component 1')\n",
    "subplots[0].set_ylabel('Principal component 2')\n",
    "subplots[1].scatter(npX[:,0], npX[:,2], color=Y.color, alpha=0.5)\n",
    "subplots[1].set_xlabel('Principal component 1')\n",
    "subplots[1].set_ylabel('Principal component 3')\n",
    "subplots[2].scatter(npX[:,1], npX[:,2], color=Y.color, alpha=0.5)\n",
    "subplots[2].set_xlabel('Principal component 2')\n",
    "subplots[2].set_ylabel('Principal component 3')\n",
    "# Ajout de la légende\n",
    "for i, drug_class in enumerate(distinct_drug_classes):\n",
    "    subplots[2].scatter(0,0, color=color_names[i], label=drug_class)\n",
    "subplots[2].legend()\n",
    "\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le package *seaborn* est installé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import seaborn as sn\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Seaborn n'est pas installé, passons.\")\n",
    "else:\n",
    "    for k in range(3):\n",
    "        Y['pc_{}'.format(k)] = npX[:,k]\n",
    "    sn.pairplot(Y[[*['pc_{}'.format(k) for k in range(3)], 'DrugClass']], hue='DrugClass', palette=color_dict, \n",
    "                corner=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question** En inspectant Y, on remarque qu'on a aussi l'information concernant la nature expérimentale du datapoint : contrôle positif, négatif, ou expérience. Pouvez-vous refaire les plots ci-dessus en ajoutant cette information ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification\n",
    "\n",
    "Pour cette étape, on se restreint aux datapoints dont la classe est connue, mais également à la dose pour laquelle la substance utilisée est active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Je repère les points inutiles\n",
    "wh = np.where((Y.DrugClass=='Unknown')|(Y.Active==False))[0]\n",
    "\n",
    "# Je supprime les lignes correspondantes dans les données\n",
    "active_Y = Y.drop(wh, axis=0)\n",
    "active_X = np.delete(X.values, wh, 0)\n",
    "\n",
    "print('Nb de points restants : ', active_X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Peut-on afficher le nombre de points par classe ? Quelle est la difficulté par rapport aux difficultés énoncées tout à l'heure ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Nous allons tester les forêts aléatoires, en utilisant le package scikit-learn. Toute la documentation se trouve sur le site : https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On choisit les forêts aléatoires comme hypothesis space\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# On apprend le modèle sur les données :\n",
    "model.fit(active_X, active_Y.DrugClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on peut regarder l'erreur du modèle, et notamment la matrice de confusion. L'entrée (i, j) de cette matrice indiquera combien de points avec le vrai label *i* ont été prédits dans la class *j*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score\n",
    "\n",
    "predicted_Y = model.predict(active_X)\n",
    "score = recall_score(active_Y.DrugClass, predicted_Y, average='micro')\n",
    "print(\"Model accuracy: \", score)\n",
    "\n",
    "conf_mat = confusion_matrix(active_Y.DrugClass, predicted_Y)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Plutôt pas mal ! Mais est-on sûr de ne pas être en train d'overfitter sérieusement ?\n",
    "\n",
    "**Question** Séparez les données en un ensemble d'entraînement et un ensemble de test, pour entraîner un nouveau modèle sur l'entraînement et obtenir une meilleure estimation de l'erreur qu'il aurait sur des données qu'il n'a jamais vues. On pourra utiliser la classe suivante : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Avec un petit réseau de neurones. On pourra utiliser la classe suivante : https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "\n",
    "Pour aller plus loin, on peut conseiller PyTorch (https://pytorch.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Ici il est important de normaliser les données avant de les utiliser.\n",
    "nactive_X = (active_X - np.mean(active_X, 0))/np.std(active_X, 0)\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', batch_size=200, verbose=10)\n",
    "model.fit(nactive_X, active_Y.DrugClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Quelle est l'accuracy du modèle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Essayez de faire varier le nombre de couches et le nombre de neurones de chaque couche."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
